
% DOCUMENT CLASS
\documentclass[oneside,12pt]{article}

\usepackage{hyperref}

\usepackage{graphicx}
\usepackage[dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{verbatim}

\usepackage{amsmath}
\usepackage{mathtools}

\usepackage{agda}

\input{font-business}

% Caption options
\usepackage[font=footnotesize,labelfont=bf]{caption}

\usepackage{lipsum}

% Bold face small caps
% \usepackage{bold-extra}

%\input{unicode}
%\usepackage{eufrak}
%\usepackage{mathabx}
% Use Chancery Font


% Includes "References" in the table of contents
\usepackage[nottoc]{tocbibind}


\usepackage{epigraph}
\usepackage{varwidth}

\usepackage{ stmaryrd }% For \llbracket \rrbracket
% Used in \tctrip def




% For NB ligature
\newcommand\NB[1][0.1]{N\kern-#1emB \,} % default kern amount: -0.3em

% Style for Agda snippet math script replacement
% (emphasised agda definitions)
\newcommand{\agdamath}[1]{\emph{\texttt{\!#1}}}

% style for Mini-Imp construct/mechanism
\newcommand{\impcode}[1]{\textsc{\texttt{#1}}}

\newcommand{\codevar}[1]{\ensuremath{\mathpzc{#1}}}

\newcommand{\textM}[1]{\ensuremath{\mathpzc{#1}}}

% For constants in agda-snippets
% Place input in circle (arg should be one numeral 1-9)
\newcommand{\constv}[1]{\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {#1}}}}

% Hoare's original notation for partial correctness
% \newcommand{\hpc}[3]{\textM{#1 } \{\!\!\{\  \textM{ #2 }  \}\!\!\} \textM{ #3}}
\newcommand{\hpc}[3]{\! \textM{#1} \;  \{\!\!\{ \; \textM{#2} \;  \}\!\!\}  \; \textM{#3} \!}
% Inline version with tighter spacing
\newcommand{\hpcil}[3]{ \!\!\!  \textM{#1} \!\!\!  \{\!\!\{  \textM{#2}  \}\!\!\}  \!\!\! \textM{#3} \!\!\!  }

% Gries then uses this for total correctness, but confusingly in many
% expositions these days it is used to denote partial correctness!
\newcommand{\gtc}[3]{\!  \{\!\!\{ \; \textM{#1} \; \}\!\!\} \; \textM{#2} \;  \{\!\!\{ \; \textM{#3} \; \}\!\!\} \!}
% Inline version with tighter spacing
\newcommand{\gtcil}[3]{ \!\!\!\!   \{\!\!\{  \!\!\!  \textM{#1} \!\!\! \}\!\!\} \textM{#2}   \{\!\!\{  \!\!\! \textM{#3} \!\!\!  \}\!\!\} \!\!\!  }

% This reports/project's notation
% Partial Correctness Hoare-Triple
\newcommand{\pctrip}[3]{\large{\guillemotleft}\normalsize{$#1$}\large{\guillemotright}%
  \normalsize{$#2$}\large{\guillemotleft}\normalsize{$#3$}\large{\guillemotright}\normalsize}

% Total Correctness Hoare-Triple
\newcommand{\tctrip}[3]{$\large{\llbracket}\normalsize{#1}\large{\rrbracket}\,%
  \normalsize{#2}\,\large{\llbracket}\normalsize{#3}\large{\rrbracket}\normalsize$}


\newcommand{\wpre}[2]{$\textit{wp}(#1,#2)$}

\newcommand{\wlpre}[2]{$\textit{wlp}(#1,#2)$}

% Agda code state transformer symbol
\newcommand{\stateT}{\ensuremath{S\Delta}}

% def above equal sign
\newcommand{\eqdef}{$\stackrel{\text{\tiny def}}{=}$}

% filled circle (empty state) symbol
\newcommand{\circfill}{\tikz\draw[black , fill=black] (0,0) circle (.6ex);}


\begin{document}

\begin{titlepage}
  \begin{center}
    \large

    \textbf{\Large A Constructive Formalisation of Hoare Logic within the Interactive Theorem Prover Agda}

    
    \vfill

    Project Report \\
    Word Count: 10,000  \\
    Fraser L. Brooks 1680975 \\
    Supervisor: Vincent Rahli
    
    \vfill
    \includegraphics[width=4cm]{Figures/birmingham_shield.png}
    \vfill
       
    Submitted in partial fulfillment \\
    of the requirements for the degree of\\
    Master of Science \\
    (Computer Science) \\
       
    \vfill
       
    at the \\
    University of Birmingham\\
    School of Computer Science\\
    July 2021
       
    \vspace{0.8cm}
       
  \end{center}
\end{titlepage}

\flushbottom

\renewcommand{\abstractname}{Introduction}
\begin{abstract}

  Program correctness is a perennial problem for software engineers and computer scientists alike. Many methods exist for establishing the correctness of a program, and broadly speaking these methods fall into one of two paradigms; a program can be tested for correctness or the correctness can be `proved' outright. Due to the sheer complexity of software engineering, testing has reigned supreme in industry as formal techniques for proving correctness, while numerous, have lagged behind practice.
  However, with the advent of higher-order-logic theorem provers and dependently typed programming languages, both operating under the scope of the Curry-Howard correspondence, the gap between practice and theory is shrinking.

  Hoare logic is a formal system in which one can reason rigorously about --- and \emph{prove} --- the correctness of programs while Agda is both a dependently typed programming language \emph{and} an interactive theorem prover in accordance with the Curry-Howard correspondence. Combining the two, this work sets out to formalise the salient rules from Hoare logic within Agda and, in doing so, provide a novel library with which a user could reason and prove correct simple imperative-style programs.

  This formalisation was achieved via a deep embedding of both a simple imperative language, dubbed \emph{`Mini-Imp,'} and of a propositional calculus used in the reasoning about programs in the guise of Mini-Imp's expression language. Agda record interfaces were also used to separate out the concerns of proving program correctness and proving trivial results within the expression language --- such as conjunction elimination or the distributivity of multiplication over addition.

  The final result is a constructive formalisation of Hoare logic and an Agda library that is fit for the purpose of proving correct simple imperative-style programs using the implemented Hoare logic rules. A limitation of the work is the simplicity of the Mini-Imp language and corresponding lack of more sophisticated logical rules, meaning there is no facility for reasoning about more complex language constructs like procedures, arrays or pointers. However, more powerful logics such as `separation logic' could bridge this gap and owing to the expressive power of HOL, with time, there is no reason why the current library couldn't be expanded to encompass separation logic too.

  \end{abstract}

\pagebreak
  
\tableofcontents

\pagebreak

\raggedbottom

\section{Preliminaries \& Literature Review}


%\begin{chapquote}{David Gries, \emph{The Science of Programming}}
 % ``Programming began as an art''
%\end{chapquote}


\subsection{Programming Language Semantics}

\epigraph{``Programming began as an art''}{ \tiny - David Gries, \emph{The Science of Programming}}


Around the late 60s -- early 70s, in response to the verbose and inelegant languages of the time --- some of which, sadly, are still in use today --- computer scientists were experimenting with different ways of giving semantics to programming languages. The desire being partly to assist in the development of more elegant languages but also partly to get a better mathematical grip on the process of computer programming and, in doing so, make a science out of the art.


Early approaches to language specification and semantics fell into what would become the category of \emph{operational} semantics\footnote{In 1968 an operational semantics was given for Algol 68. Even earlier, in 1960, the lambda calculus --- the semantics of which is commonly understood as operational --- was evoked in giving semantics to the Lisp programming language.}  that describe a language in terms of how it is to be executed. Thus demonstrating that the most salient interpretation of a program at the time was as a set of instructions destined for execution by a machine\footnote{And this meant the \emph{specific} and often competing machines of the time.} rather than as a syntactic representation of the mathematical \mbox{object} known as an \emph{algorithm}. This lead to languages being designed with the machines that would run them, and the programmers that would use them, in mind. This led to a state of affairs wherein reasoning about the correctness of programs was much harder than it needed to be and was seen as not worth the effort.


As Dijkstra remarked at the time, the balance needed `redressing' thus leading to a couple of seminal papers, first by Hoare\cite{hoare1969axiomatic} and then himself\cite{Dijkstra75}--- the latter, in part, inspired by the former. Hoare introduced \emph{axiomatic} semantics as a means to understanding computer programs via the assertions that can be said to be true before and after execution.\footnote{Regardless of how that execution is performed!} Then Dijkstra introduced a \emph{predicate transformer} semantics identifying language constructs with functions between preconditions and postconditions --- and thus, the balance between practical power and mathematical elegance and rigour began to find more equitable ground.



\subsubsection{Axiomatic Semantics via Hoare Logic}


In 1967, as an alternative to operational semantics, Floyd\cite{Floyd1967Flowcharts} produced his seminal paper `Assigning Meanings to Programs' in which a program is given semantics via attachment of propositions to the connections in a flow chart with nodes as commands. In Floyd's deductive system, whenever a command (a node) is reached via a connection whose associated proposition is true, then, if execution of the program leaves that node, it will leave through a connection whose associated proposition is also true.

\begin{quote}

``A \emph{semantic definition} of a particular set of command [program] types, then, is a rule for constructing, for any command \textM{c} of one of these types, a \emph{verification condition} \textM{V_c(P;Q)} on the antecedents and consequents of \textM{c}''. - \footnotesize Floyd\cite{Floyd1967Flowcharts}

\end{quote}

The principle idea is that rather than define a program (however large or small) by the way it should be executed, a program can be defined by the antecedents upon the state space that must be true before execution --- hereafter referred to as \emph{preconditions} --- and the associated consequents upon the state space that can be guaranteed to be true after execution --- hereafter referred to as \emph{postconditions} --- thus freeing the semantics from concerns of the \emph{how} in favour of the \emph{what.}


These `antecedents/consequents upon the state space' are first-order logic predicates or propositions and the state space is taken most generally to be a set of pairs of identifiers and values; again the formulation here shields us from implementation details such as whether these `identifiers' identify memory addresses within a machine or Post-it Notes on a wall.

Later then, in 1969, Hoare\cite{hoare1969axiomatic} built upon and expanded Floyd's work\footnote{Thus Hoare logic is sometimes referred to as Floyd-Hoare Logic}, applying the system to text rather than to flow charts, creating a \emph{deductive system} for reasoning about the correctness of programs as we would more naturally recognise them. Central to Hoare's system is the notion of a \emph{Hoare triple} which is a reformulation of Floyd's verification condition \textM{V_c(P;Q)}. A Hoare triple associates a precondition, or a state, before execution of a particular program with a resultant postcondition, or state, after execution.\footnote{\NB Here, as in much of the literature, preconditions and postconditions and the actual subsets of the state space that they describe are used interchangeably. i.e. $\impcode{False} = \emptyset$ and $\impcode{True} = \textM{S}$ where $\textM{S}$ is the whole state space.} 

\pagebreak

A Hoare triple is of the form `\gtcil{P}{Q}{R}' which can be read as \ldots

\begin{itemize}
\item If the notation is to denote \emph{partial correctness}:
  \begin{itemize}
  \item If execution of the program \textM{Q} begins in a state satisfying \textM{P}: then \textM{R} will be true of the resultant state \emph{so long as} \textM{Q} terminates.
  \end{itemize}
\item If the notation is to denote \emph{total correctness}:
  \begin{itemize}
  \item As above, but termination of \textM{Q} is also guaranteed.
  \end{itemize}
\end{itemize}

\begin{centering}

  \fbox{
    \;
    \parbox{0.94\textwidth}{
      \vspace{0.4em}
      \small A note on notation: Hoare's original notation was \mbox{\hpcil{P}{Q}{R}} to denote \emph{partial correctness} but the notation above is now more common. Confusingly, some use \mbox{\gtcil{P}{Q}{R}} to denote \emph{total} correctness and the other form for partial correctness. In general there seems to be no standard notation, with the \mbox{\gtcil{P}{Q}{R}} form oft used for the form of correctness most salient for a given work; as such, in this report, the \mbox{\gtcil{P}{Q}{R}} denotes partial correctness.
      \vspace{0.4em}
    }
    \;
  }

\end{centering}

\vspace{1em}

The utility of the Hoare triple notation is then immediately demonstrated by giving the Hoare triple that characterises the statement/command that assigns a value to a variable:

\begin{centering}

  \begin{tabular}{l}
    \, \\
    Given the expression \codevar{f} and assignment statement  `\codevar{x} \impcode{:=} \codevar{f}':   \\
    \, \\
    \multicolumn{1}{c}{\gtcil{P_0}{\codevar{x} \, \impcode{:=} \, \codevar{f}}{P}} \\
    \, \\  
    \ldots where \textM{P_0} is formed by substituting \codevar{f} for \codevar{x} in \textM{P} (\textM{P_0} = \textM{P[f/x]}). \\
    \, \\    
  \end{tabular}

\end{centering}

Note that in general \gtcil{P}{Q}{R} is a predicate within the predicate calculus (see \ref{eq:hoare-trip=wp}) that can either be true or false, depending on the arguments supplied. The triple given above, however, is actually the first and only \emph{axiom}\footnote{In actuality, it is an axiom \emph{schema} describing an infinite set of axioms all sharing a common form.} in Hoare's system as it is true for all possible \textM{P}, \codevar{f}, and \codevar{x}. \footnote{A fact that is proved constructively (along with the inference rules \ref{eq:D1}, \ref{eq:D2}, and \ref{eq:D3}, \mbox{described} on page \pageref{eq:D1}) as part of this formalisation.}


\vspace{1em}

\begin{centering}
  \parbox{\textwidth}{
    \begin{equation}
      \label{eq:D0}
      \mbox{D0 - Axiom of Assignment: }\vdash \gtc{P[f/x]}{\codevar{x} \, \impcode{:=} \, \codevar{f}} {P}
    \end{equation}
    }
\end{centering}




This first example not only demonstrates the utility and elegance of the Hoare triple but also shines a light on two of the stumbling blocks of Hoare logic. The first of these is the substitution of the programming language expression \textM{f} into the predicate \textM{P} thus indicating an interplay between the expression language and the assertion language --- the assertion language, being, the language from which preconditions and postconditions are to be formed. In theory, and in practice, this interplay isn't a problem so long as the assertion language is more expressive than the program's expression language. So long as this condition is met there will always be \emph{some} sensible, well-defined way of substituting an expression into an assertion and because there is never a need to substitute in the opposite direction, no further \mbox{complications} arise.\footnote{Within this formalisation however, this stumbling block does present a challenge as it forces upon us a number of considerations. See \autoref{sec:spec:expression-assertion-lang} }

\label{page:expassertionprob}

The second stumbling block is that at first, to many, the reasoning appears to be happening in the wrong direction. From starting condition \textM{P}, we substitute to get \textM{P_0}, that is, we move from postcondition to precondition when to many programmers, reasoning in the direction of execution feels much more natural. The axioms that match the standard programmer's intuition are:

\begin{center}
  $\begin{array}{l}
     \mbox{(1.) } \; \; \vdash \gtc{\;P\,}{\codevar{x} \, \impcode{:=} \, \codevar{f}} {\;\,P[x/f]\;}\;\; \\ \mbox{or \ldots} \\
     \mbox{(2.) } \; \; \vdash \gtc{\;P\,}{\codevar{x} \, \impcode{:=} \, \codevar{f}} {\;\,P[f/x]\;}
  \end{array}$
\end{center}

\ldots but both of these are erroneous. The first gives the false consequent $\vdash \gtc{\codevar{x} = 1}{\codevar{x} \, \impcode{:=} \, \codevar{0}}{\codevar{x} = 1}$ as a direct consequence of the fact that $(\textM{\codevar{x}=1})[0/\codevar(x)]\, = \, (\textM{\codevar{x}=1})$; as $0$ doesn't occur in `$\textM{\codevar{x}=1}$'. The second gives the false consequent of $\vdash \gtc{\codevar{x} = \codevar{y}}{\codevar{x} \, \impcode{:=} \, \codevar{z}}{\codevar{z} = \codevar{y}}$ via substituting \codevar{x} for \codevar{z}.


So in fact, the reasoning is in the right direction, that is, \emph{backwards}. This is in line with the radical reformulation of programming that was being proposed at the time by Hoare, and later Dijkstra, and then most lucidly expatiated upon in Gries' monograph\cite{Gries81}, `The Science of Programming.' This reformulation was to frame programming as a \emph{goal-oriented} activity and to construct programs alongside a proof of correctness, starting with the desired postcondition --- the desired output --- and working backwards towards the necessary precondition/input.\footnote{As a result, proofs of correctness constructed using the Agda library produced by this project are also constructed backwards. See figure \ref{fig:swap-proof}}



So we've seen the characterisation of the assignment command as an axiom. In Hoare's original paper, the following inference rules were also given, from which proofs of correctness could be developed, starting with the fairly intuitive rules of consequence:

  
\begin{equation}
  \label{eq:D1}
  \begin{array}{c}
    \mbox{D1 - Rules of Consequence: } \hspace*{\fill} \\
  \end{array}
\end{equation}  $
  \begin{array}{c}
    \hspace{\textwidth} \vspace{-1em} \\      
    \mbox{\!\!If\;\;\;\;} \vdash \gtc{P}{Q}{R} \mbox{\;\;\;\;and\;\;\;\;} \vdash \textM{R} \Rightarrow \textM{S} \mbox{\;\;\;\;then\;\;\;\;} \vdash \gtc{P}{Q}{S}\\[0.25em]
    \mbox{\!\!If\;\;\;\;} \vdash \gtc{P}{Q}{R} \mbox{\;\;\;\;and\;\;\;\;} \vdash \textM{S} \Rightarrow \textM{P} \mbox{\;\;\;\;then\;\;\;\;} \vdash \gtc{S}{Q}{R}
  \end{array}
  $

\vspace{2em}

Next up is the rule of composition which is the rule that allows us to chain Hoare triples together to build up larger proofs of correctness for programs from the proofs of correctness of these programs' constituent parts.

  
\begin{equation}
  \label{eq:D2}
  \begin{array}{c}
    \mbox{D2 - Rule of Composition: } \hspace*{\fill} \\
  \end{array}
\end{equation}$
\begin{array}{c}
  \hspace{\textwidth} \vspace{-1em}\\
  \mbox{\!\!\!If\;\;} \vdash \gtc{P}{Q_1}{R_1} \mbox{\;\;\; and\;\;} \vdash \gtc{P}{Q_1}{R_2} \mbox{\;\;then\;\;} \vdash \gtc{P}{Q_1 \; ; Q_2}{R}
\end{array}$


\vspace{2em}

Finally the most interesting rule, the rule of iteration:

\begin{equation}
  \label{eq:D3}
  \begin{array}{c}
    \mbox{D3 - Rule of Iteration: } \hspace*{\fill} \\
  \end{array}
\end{equation}$
\begin{array}{c}
  \hspace{\textwidth} \vspace{-1em}\\
  \mbox{\!\!\!If\;\;} \vdash \gtc{\textM{P} \wedge \textM{B}}{S}{P} \mbox{\;\;then\;\;} \vdash \gtc{P}{\impcode{while} \;\; \textM{B} \;\; \impcode{do} \;\; \textM{S}}{\neg \textM{B} \wedge \textM{P}}
\end{array}$

\vspace{2em}


The insights on display here are that \emph{if} a loop terminates, then we can be sure that the condition \textM{B} of the loop is now false, and that if we have a condition \textM{P} that we know isn't changed by the running of the body of the loop so long as it is ran when the loop condition \textM{B} is also true ($\vdash \gtc{\textM{P} \wedge \textM{B}}{S}{P}$), then we can also be sure that \textM{P} is true \emph{after} the loop terminates. And thus the, now well known, notion of a loop \emph{invariant} has been introduced.

This was one of the first contributions of the \emph{theory} of programming to the practice, viz, that when designing a loop, we should start with the desired postcondition \textM{R} and search for a \textM{P} and \textM{B} fitting the schema above --- i.e. A \textM{P} and \textM{B} such that $\textM{P} \wedge \neg \textM{B} \Rightarrow \textM{R}$ --- at which point we'll have the condition of the loop \emph{and} its precondition and all that shall be left to do is fill in the body of the loop; which we'll be able to do safely by making sure that \textM{P} is left invariant, and execution moves towards the falsity of \textM{B}.




\subsubsection{Predicate Transformer Semantics via \\ Dijkstra's \emph{Weakest Precondition}}

\epigraph{``Program testing can be used to show the presence of bugs, but never to show their absence!''}{ \scriptsize - Edsger W. Dijkstra, 1970 }

Very early on in the field of computing science, Dijkstra, among others, was also interested in putting programming on surer mathematical footing; moving away from the notion of programming as a `chaotic contribution' of `thousands of ingenious tricks' as it was put in his talk `Some meditations on Advanced Programming'\cite{Dijkstra62}, at the 1962 IFIP conference.

Despite some disagreements between industry and academics --- or rather, the theoretically inclined academics --- as the 60s progressed and the programs being developed grew in scope, it became apparent that Dijkstra and similar detractors of the status quo were right and that there were serious problems with programming. Hoare's paper had spawned a field of research on axiomatic definitions of programming languages, and many papers were born from this, but the utility of the approach was still subject to doubt. Axiomatic definitions provided a way to reason about programs, but didn't so much present a way to \emph{develop} them.

Then, in 1975, building upon Hoare's paper, Dijkstra carried the notion of an axiomatic semantics further in his very influential paper `Guarded Commands and Non-Determinism'\cite{Dijkstra75} --- followed up by the monograph `A Discipline of Programming'\cite{Dijkstra76} --- in which he introduced the notion of a \emph{predicate transformer semantics}.\footnote{As well as introducing the notion of guarded commands still very much present in languages today}



Whereas Hoare logic characterises programming constructs in terms of logical assertions upon the state space, the idea behind predicate transformer semantics is to characterise a programming construct in terms of a `predicate transformer', that is, a function that transforms one predicate into another.\footnote{Being a \emph{function}, that makes predicate transformer semantics a form of \emph{Denotational Semantics}; that is, semantics defined via reference to mathematical objects.} Thus was born Dijkstra's, now well known, \emph{Weakest Precondition}; usually denoted \textM{wp(S,R)} for a command \textM{S} and postcondition \textM{R}.


It's useful to keep the two views in mind, that the weakest precondition is both a predicate but also a means of \emph{characterising} a particular programming construct. It is defined for a command \textM{S} and a predicate \textM{R} that describes the desired result of executing command \textM{S} --- that is, \textM{R} is the desired postcondition --- as the predicate, \textM{wp(S,R)}, that represents/captures:


\begin{quote}

``the set of \emph{all} states such that execution of \textM{S} begun in any one of them is guaranteed to terminate in a finite amount of time in a state satisfying \textM{R}.'' - \footnotesize Gries\cite{Gries81}

\end{quote}


\begin{centering}

  \fbox{
    \;
    \parbox{0.94\textwidth}{
      \vspace{0.4em}
      \small \NB The term `weakest' here, means the least restrictive predicate, or, if we consider assertions as the subset of the state space they describe, then \mbox{`weakest'} can be taken to mean the predicate with the highest cardinality.

      The guarantee of termination means we're reasoning about \emph{total} correctness. There is a closely associated notion of a  weakest \emph{liberal} precondition, defined identically, but without the guarantee of termination,\footnotemark and denoted \textM{wlp(S,R)}. 
      \vspace{0.1em}
    }
    \;
  }\footnotetext{And as such, is the more relevant predicate transformer for this work as constructive or formal proofs of termination is a field unto itself that is not treated in this formalisation.}

\end{centering}

\vspace{1em}



The relation to Hoare logic should now be clear and indeed, \textM{wp(S,R)} can be defined in terms of Hoare logic: we can say that for a particular command \textM{S}, and a postcondition \textM{R}, such that \textM{R} is the desired result of executing \textM{S}, then the weakest precondition is a predicate \textM{wp(S,R)}, such that for any precondition \textM{P}, we have \gtcil{P}{S}{R} if and only if $\textM{P} \Rightarrow \textM{wp(S,R)}$.

\begin{centering}
  \begin{equation}
    \label{eq:hoare-trip=wp}
    \begin{aligned}
      \hpc{P}{S}{R} \;\;\;\; &= \;\;\;\; \textM{P} \Rightarrow \textM{wp(S,R)} \\
      \, \\
      \gtc{P}{S}{R} \;\;\;\; &= \;\;\;\; \textM{P} \Rightarrow \textM{wlp(S,R)}
    \end{aligned}
  \end{equation}
\end{centering}


This shows, as remarked previously, that a Hoare triple is just a statement within the underlying predicate calculus and proving a Hoare triple --- i.e. a \emph{program} --- correct, is reduced to the task of proving a \emph{first-order formula}! 

The contribution of predicate transformer semantics, as a reformulation of Hoare logic, is that it lay the groundwork for a new (at the time) paradigm of programming, a \emph{science of programming}\cite{Gries81}, such that for the first time, programmers could use theory to develop programs \emph{alongside} a proof of correctness, rather than resorting to `ingenious' but `chaotic' tricks.

As a slight diversion, then, what does defining a language in terms of \textM{wp} look like? The simplest commands that can be characterised by their weakest preconditions are the \agdamath{skip} command, that does nothing, characterised by `$\textM{wp}( \agdamath{skip}  ,\textM{R}) = \textM{R}$', and the \agdamath{abort} command --- that aborts computation and signifies failure, characterised by `$\textM{wp}( \agdamath{abort}  ,\textM{R})  = \agdamath{False}$.'

A more interesting example that should be familiar is the assignment command as a reformulation of the axiom of assignment from Hoare logic:

\begin{centering}
  \begin{equation}
    \label{eq:wp-assi}
    \textM{wp}(\codevar{x} \, \impcode{:=} \, \codevar{f},\textM{R}) \;\;\;\; = \;\;\;\; \textM{R[f/x]}
  \end{equation}
\end{centering}



A, more interesting still, example would be a characterisation of a simple `\impcode{IF\ldots THEN\ldots ELSE}' command:


\begin{centering}
  \begin{equation}
    \label{eq:wp-ifelse}
    \begin{aligned}
      \!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\! \textM{wp}( \impcode{IF} \;\; \textM{B} \;\; \impcode{THEN} \;\; \textM{S_1} \;\; \impcode{ELSE} \;\; \textM{S_2} \;\; ,\textM{R}) \;\;\;\; =& \\
      & \;\;\,\;\;\;\;\;\;  \textM{B} \Rightarrow \textM{wp(S_1 , R)} \\
      & \wedge \;\; \neg  \textM{B} \Rightarrow \textM{wp(S_2 , R)}
    \end{aligned}
  \end{equation}
\end{centering} 


A weakest precondition for a \impcode{while}/iteration command becomes a little more involved as it has to be defined inductively, similar to the above definition, only in a way that guarantees progress towards termination. As such, it is not repeated here; the definitions above have been given only for pedagogical reasons to situate the Hoare logic calculus and the rules formalised in this work fully within their understood context.\footnote{\NB That the definitions given here differ significantly from those in \cite{Dijkstra75}/\cite{Dijkstra76} wherein the language that is defined is non-deterministic, a fact that to many a programmer might sound alarming but in actuality makes for a much `cleaner' language.}

Thankfully for Hoare logic and this formalisation, it is rarely necessary to formulate/compute the weakest precondition itself. In so far as our concerns are to prove the correctness of programs, it is enough to show that for a given precondition \textM{P}: $\textM{P} \Rightarrow \textM{wp(S,R)}$. Indeed, for the Hoare logic inference rules \ref{eq:D1},\ref{eq:D2}, and \ref{eq:D3},  given in the previous section, proofs that they do actually imply what they claim are given in \cite{Dijkstra76}/\cite{Gries81}. For instance, see theorem (11.6) in \cite{Gries81}, or the proof of the `Fundamental Invariance Theorem' in \cite{Dijkstra76} for a proof that any \textM{P} that satisfies a more general, non-deterministic, version of the Rule of Iteration from the previous section, does in fact imply the weakest precondition of the \impcode{while}/iterative command as given in those same works.


\subsection{Agda as an Interactive Theorem Prover}


\epigraph{ ``Beware of bugs in the above code; I have only proved it correct, not tried it.''}{ \scriptsize - Donald Knuth, 1977}


With Hoare logic and programming language semantics covered, the other prerequisite to understanding this report's title is to briefly explain the phrases `Constructive Formalisation' and `Interactive Theorem Prover.'

\subsubsection{Formal Proof}

First up, the word `formalisation', as in, a \emph{formal} proof. What is a formal proof? Well, according to \emph{Merriam-Webster's} online dictionary, a proof is:

\begin{quote}
  ``the cogency of evidence that compels acceptance by the mind of a truth or a fact''
\end{quote}


What exactly this `evidence' should be is left unspecified. In a \emph{formal} proof, this evidence is situated within some logical system. It is a string of symbols or sentences that form a \emph{well-formed formula} within a formally defined language --- read, a language that has been described by precise and unambiguous rules --- each of which has a precise and unambiguous meaning and is either an \emph{axiom} within the logical system, an \emph{assumption}, or follows from one of the logical system's inference rules. Put very simply then, a formal proof is just a very assiduous, unambiguous, sometimes tedious, proof. 


\subsubsection{Constructive Mathematics}


Constructive mathematics, or constructive logic, refers to mathematical or logical reasoning within the \emph{constructivism} philosophy of mathematics. It is often characterised as classical mathematics or logic, only without the \emph{Law of Excluded Middle} and the \emph{Axiom of Choice.}\footnote{Necessarily without the Axiom of Choice as the Axiom of Choice implies the Law of Excluded Middle within a constructive setting.} The law of the excluded middle, sometimes called the \emph{principle} or \emph{axiom} of the excluded middle by constructivists to emphasise the optionality, is the axiom stating that every proposition is either true or false; that is, $\forall \textM{P} . \textM{P} \vee \neg \textM{P}$. At first glance it seems an obvious, even banal, tool to allow oneself; indeed it is a very useful principle in logic upon which many famous proofs rely. So why reject it?

The beginnings of the constructivist philosophy can be traced back to early 20th century thought led by Brouwer. The main concern of constructivism is in how one asserts that a mathematical object does or does not exist. The problem with LEM is that it allows one to assert the existence of mathematical objects without actually specifying \emph{what} they are, that is, without \emph{constructing} them. Consider the following classical proof:


\begin{center}
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\end{center}


{\small

\vspace{-0.5em}

\noindent{\texttt{Theorem: There are irrational numbers $a$ and $b$ such that $a^{b}$ is rational.}}

\vspace{0.5em}

\noindent{\texttt{Proof:}}

\noindent{\texttt{Let $c = \sqrt{2}^{\sqrt{2}}$ and let $P(x) = $ "$x$ is rational".}}

\noindent{\texttt{Via LEM, either $P(c)$ or $\neg P(c)$.}}

\vspace{0.5em}

\noindent{\texttt{If $P(c)$:}}

$\qquad \qquad$\noindent{\texttt{let $a = b = \sqrt{2}$,}}

$\qquad \qquad$\noindent{\texttt{then we have $a^{b} = c$,}}

$\qquad \qquad$\noindent{\texttt{therefore $P(a^{b})$ via $P(c)$.}}


\noindent{\texttt{If $\neg P(c)$:}}

$\qquad \qquad$\noindent{\texttt{let $a = c = \sqrt{2}^{\sqrt{2}}$,}}

$\qquad \qquad$\noindent{\texttt{let $b = \sqrt{2}$,}}

$\qquad \qquad$\noindent{\texttt{then we have:}}

$\qquad \qquad a^{b} = \bigl(\sqrt{2}^{\sqrt{2}}\bigr)^{\sqrt{2}} = \sqrt{2}^{\sqrt{2} \sqrt{2}} = \sqrt{2}^{2} = 2$

$\qquad \qquad$\noindent{\texttt{therefore $P(a^{b})$ via $P(2)$.}}

\vspace{0.5em}

\noindent{\texttt{So the theorem holds for both $P(c)$ and $\neg P(c)$, and so\ldots  \hfill  QED$\blacksquare$ \hfill }}

}

\begin{center}
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\end{center}


It's not that constructivists doubt the validity of this proof. The objection is that the object under question --- some irrational numbers $a$ and $b$ such that $a^b$ is rational --- hasn't actually been given. We don't know which of the two cases, $P(c)$ or $\neg P(c)$, is true.

So, rather than characterise constructive mathematics as classical mathematics without the law of the excluded middle, it perhaps can be better described positively as an approach to mathematics with stricter provability requirements wherein a thing can be said to exist only \emph{after} constructing it.

With all that said, it is not necessary to get caught up in the philosophical arguments or the nuances of constructivism for this present work. The primary motivation here is that often constructive treatments of classical results can often prove stronger and more illuminating.


Also of our concern, is that with the rise of the computer, constructive mathematics has come into its own. A constructive proof can be read as an \emph{algorithmic} proof --- read, checkable or usable by a computer. As an example, consider the proof given just now, if we wished to do something algorithmically with the $a^b$-object that was proved to exist, the proof given there wouldn't be much use to the machine or the programmer; a computer cannot proceed in two minds at once! Thus, the utility of constructive mathematics has never been clearer, and this leads to a contribution that computer scientists have given the world of mathematics; the subject of the next section.


\subsubsection{Interactive Theorem Provers}

Interactive Theorem Provers, or proof assistants, are broadly characterised as software systems used as an aid in the development of proofs. An early demonstration of the use of a computer to aid mathematical endeavour is given by Knuth and Bendix in 1970\cite{KNUTH1970263} in which an algorithm was devised which was capable of deducing new laws or theorems from some given ones; some laws of elementary group theory serving as an exmple within the paper. The formal development of this algorithm, in the authors words was `primarily a precise statement of what hundreds of mathematicians have been doing for many decades.'


Of course, the development of mathematics with computational aid has come a long way since then and there are now a plethora of so called `Interactive Theorem Provers' to choose from. The principle idea behind all of them is that mathematical objects can be represented as \emph{data}, sometimes, also referred to as a \emph{word}, inside a machine and mathematical operations or laws can be implemented as operations upon that data/word. These operations might be referred to as \emph{reductions}. For example, we can encode in data, or as \emph{words}, the natural numbers \`{a} la Peano as follows:

\vspace{0.3em}

\texttt{A natural number is inductively defined as either:}

\begin{enumerate}
\item  The word/data: \AgdaInductiveConstructor{``zero''}
\item  Or the word/data: \AgdaInductiveConstructor{``suc $\mathpzc{x}$''} where \AgdaInductiveConstructor{$\mathpzc{x}$} is some other natural number.
\end{enumerate}



Addition over natural numbers can then be quite simply defined on a case by case basis of the inputs:


\begin{center}
  \begin{minipage}{.75\textwidth}
    \texttt{ x + y  \; \eqdef \,}
    \begin{varwidth}{\textwidth}
    \begin{enumerate}
    \item  \texttt{x} $= 0$ : \;\;\;\;\; \AgdaInductiveConstructor{``zero + \texttt{y}''} =  \AgdaInductiveConstructor{``\texttt{y}''}
    \item  \texttt{x} $\neq 0$ : \;\;\;\;\;  \AgdaInductiveConstructor{``suc $\mathpzc{x}$ + \texttt{y}''} =  \AgdaInductiveConstructor{``suc ($\mathpzc{x}$ + \texttt{y})''}
    \end{enumerate}
    \end{varwidth}
  \end{minipage}
\end{center}

With such a definition, it can be \emph{algorithmically} verified that $ 1  +  1 \; \equiv \; 2$, with $\equiv$ serving as \emph{definitional} equality, as once both terms on either side of the operator are maximally reduced, they \emph{are} the same. In addition to the above, the commutativity of addition could be proved, multiplication could be defined in terms of the definition of addition etc. In fact, there are projects operating today aiming to formalise large quantities of mathematics in this manner within particular interactive theorem provers. For instance, the UniMath project is a huge library of mathematics formalised within the Coq interactive theorem prover.



Within these theorem provers then, proving that $\textM{P} \Rightarrow \textM{Q}$, amounts to a search for a sequence of reductions/rules that transform the data encoding \textM{P}, into some data encoding \textM{Q}. This search is done through some degree of cooperation between the user and the machine, in some cases happening automatically, and in others requiring human intervention and ingenuity. The algorithmic nature of theorem provers following this pattern is what gives this realm of mathematics a great synergy with constructive mathematics, although it should be noted that not all interactive theorem provers have to operate under the scope of constructive mathematics.


With that said, Agda\cite{norell2007towards} is the interactive theorem prover used within this formalisation, chosen as it is a constructive system by default which means that the principle of the excluded middle, if desired, would need to be \emph{postulated} as an axiom.\footnote{A temptation that has been resisted in this formalisation.} This amounts to inserting it as a reduction rule but at the cost of our proof having algorithmic meaning, because, as was mentioned in the previous section, PEM has no computational meaning. So this restriction is what allows Agda to also claim itself a \emph{programming language} and operate under the \emph{propositions as types} paradigm, also known as the Curry-Howard correspondence, in which the type of a program as described by its signature becomes a proposition and an implementation of that program becomes a proof of that proposition. Disciplined use of Agda in this way showcases the fact that the formalisation is possible without LEM/PEM, an unsurprising, but nice to verify, fact.


\subsection{Modern Literature Review}

With most of the preliminaries out of the way, and most of them being historic, it is worth examining the picture of program correctness as it appears today. The field has come a long way despite the methodology of program development proposed by Hoare, Dijkstra, and Gries, wherein a program is developed alongside its proof of correctness, struggling to catch on in the mainstream --- likely as a result of programs continuing to swell in complexity. Hoare logic has been expanded upon, giving rise most notably to \emph{Separation Logic} which has become a success story of the theoretical world after making its way into industry in the form of the \emph{Infer} tool which is now in use in a plethora of tech companies. The Infer tool is a static analyser for Java, C, C++, and other languages, capable of catching a plethora of bugs including null pointer errors and memory leaks before they make their way into production.

Separation logic originated from a couple of papers (\cite{sep2001}/\cite{reynolds2002separation}) in which Hoare logic was extended to also facilitate reasoning about memory and pointers, thus allowing one to prove correct much more complicated and sophisticated programs rather than being limited to local variables and reasoning as you are in Hoare logic. Indeed, the original aims of this work were to formalise not only Hoare logic but separation logic as well, but this proved too much work for the time allotted.

Also of note on the modern scene is the work from a group of researchers towards a \emph{Verified Software Toolchain}\cite{vst} aiming to have a modular tool or toolchain that can statically analyse and make observations about a source-language and produce \emph{machine-checked} proofs that guarantee the complete correctness not only of the source-language but also of the compiled program operating within a particular operating system.

An interesting thing to note is that the two systems above, Infer and VST, work via the two possible relaxations of the foundational Halting Problem which of course implies that we can never expect to have a program that for \emph{all possible} programs catches \emph{all possible} bugs. The obvious workaround to this constraint is to relax one of those two constraints, with Infer opting to allow some false negatives --- and not catch all bugs --- while VST diminishes the first constraint by constraining the programmer from constructing all possible programs.


\pagebreak


\section{Specification of the Formalisation}


When formalising within a symbolic system, a lot of details that are normally swept under the rug in typical expositions need to be considered. With the preliminaries out the way then, this section details the design decisions that were made with regard to these unavoidable details, the justifications for those decisions, and finally the scope of, and overarching plan for, the formalisation at hand.

These decisions include: the choice between a deep or shallow embedding of the expression language and the programming language, the choice of programming language to model and the encoding of that language as embedded within Agda, and finally the choice of inference rules to be formalised for use within proofs of program correctness.


\subsection{Shallow vs. Deep Embedding}
\label{sec:shallowdeep}


For Hoare logic to be formalised within Agda, a simple imperative language for the Hoare logic to apply to needs to be constructed and formalised first. This language itself, will actually comprise \emph{two} languages, the language defining the commands of the language (\impcode{IF\_ELSE\_} etc\ldots) and the expression and or assertion language defining both the expressions that appear \emph{within} those commands and the assertions for the logical calculus.


Given that Agda is a programming language, then, the task is to embed one language within another; a task that is actually rather common. So-called \emph{Domain Specific Languages}, as opposed to \emph{General Purpose Languages}, are programming languages designed with a specific use case in mind. DSLs can be implemented via standalone syntax and semantics with their own compilation techniques, but often they are instead \emph{embedded} within a host language making use of that language's syntax, semantics, and compilation techniques and thus saving a lot of work for the implementer.

The choice one has to make when embedding a language within another is between a \emph{shallow embedding} or a \emph{deep embedding}. The two approaches are closely related with the principal difference being that in a shallow \mbox{embedding}, only the semantics are captured, whereas in a deep embedding the syntax itself is embedded along with some evaluation function, sometimes called an \emph{observation function}. This function then essentially provides an operational semantics to the syntax of the embedded language, while in a shallow embedding the semantics is in terms of the host language's semantics.


As an illustrative example, consider a simple expression language of \mbox{arithmetic} expressions with integer constants and addition. A deep embedding might have the form:


\begin{centering}
  \begin{code}
  \>[2]\AgdaKeyword{data}\AgdaSpace{}%
  \AgdaDatatype{\agdamath{Expr}}\AgdaSpace{}%
  \AgdaSymbol{:}\AgdaSpace{}%
  \AgdaPrimitiveType{Set}\AgdaSpace{}%
  \AgdaKeyword{where}\<%
  \\
  \>[2][@{}l@{\AgdaIndent{0}}]%
  \>[4]\AgdaInductiveConstructor{\texttt{\emph{Val}}}%
  \>[10]\AgdaSymbol{:}\AgdaSpace{}%
  \AgdaDatatype{Integer}\AgdaSpace{}%
  \AgdaSymbol{→}\AgdaSpace{}%
  \AgdaDatatype{\agdamath{Expr}}\<%
  \\
  \>[2][@{}l@{\AgdaIndent{0}}]%
  \>[4]\AgdaInductiveConstructor{\texttt{\emph{Add}}}%
  \>[10]\AgdaSymbol{:}\AgdaSpace{}%
  \AgdaDatatype{\agdamath{Expr}}\AgdaSpace{}%
  \AgdaSymbol{→}\AgdaSpace{}%
  \AgdaDatatype{\agdamath{Expr}}\AgdaSpace{}%
  \AgdaSymbol{→}\AgdaSpace{}%
  \AgdaDatatype{\agdamath{Expr}}\<%
\\
%
\\
%
\>[2]\AgdaFunction{\texttt{\emph{eval}}}\AgdaSpace{}%
\AgdaSymbol{:}\AgdaSpace{}%
\AgdaDatatype{\agdamath{Expr}}\AgdaSpace{}%
\AgdaSymbol{→}\AgdaSpace{}%
\AgdaDatatype{Integer}\AgdaSpace{}%
\\
%
\>[2]\AgdaFunction{\texttt{\emph{eval}}}\AgdaSpace{}%
\AgdaSymbol{(}\AgdaInductiveConstructor{\texttt{\emph{Val}}}\AgdaSpace{}%
\AgdaBound{n}\AgdaSymbol{)}%
\AgdaSpace{}\AgdaSymbol{=}\AgdaSpace{}\AgdaBound{n}
\\
\>[2]\AgdaFunction{\texttt{\emph{eval}}}\AgdaSpace{}%
\AgdaSymbol{(}\AgdaInductiveConstructor{\texttt{\emph{Add}}}\AgdaSpace{}%
\AgdaBound{x}\AgdaSpace{}\AgdaBound{y}\AgdaSymbol{)}%
\AgdaSpace{}\AgdaSymbol{=}\AgdaSpace{}\AgdaFunction{\texttt{\emph{eval}}}\AgdaSpace{}\AgdaBound{x}%
\AgdaSpace\AgdaSymbol{+}\AgdaSpace{}\AgdaFunction{\texttt{\emph{eval}}}\AgdaSpace{}\AgdaBound{y}%

\end{code}
\end{centering}

With observation function \texttt{\emph{eval}}. Meanwhile, a shallow embedding of the same language may have the form:

\,


\begin{centering}
  \begin{code}
    \>[2]\AgdaDatatype{\agdamath{Expr}}\AgdaSpace{}%
    \AgdaSymbol{=}\AgdaSpace{}\AgdaDatatype{Integer}%
    \\
    \\
    \>[2]\AgdaFunction{\texttt{\emph{val}}}\AgdaSpace{}%
    \AgdaSymbol{:}\AgdaSpace{}%
    \AgdaDatatype{Integer}\AgdaSpace{}%
    \AgdaSymbol{→}\AgdaSpace{}%
    \AgdaDatatype{\agdamath{Expr}}\AgdaSpace{}%
    \\
    \>[2]\AgdaFunction{\texttt{\emph{val}}}\AgdaSpace{}\AgdaBound{n}
    \AgdaSpace{}\AgdaSymbol{=}\AgdaSpace{}\AgdaBound{n}% 
    \\
    %
    \\
    %
    \>[2]\AgdaFunction{\texttt{\emph{add}}}\AgdaSpace{}%
    \AgdaSymbol{:}\AgdaSpace{}%
    \AgdaDatatype{\agdamath{Expr}}\AgdaSpace{}%
    \AgdaSymbol{→}\AgdaSpace{}%
    \AgdaDatatype{\agdamath{Expr}}\AgdaSpace{}%
    \AgdaSymbol{→}\AgdaSpace{}%
    \AgdaDatatype{\agdamath{Expr}}\AgdaSpace{}%    
    \\
    \>[2]\AgdaFunction{\texttt{\emph{add}}}\AgdaSpace{}\AgdaBound{x}
    \AgdaSpace{}\AgdaBound{y}\AgdaSpace{}\AgdaSpace{}\AgdaSymbol{=}\AgdaSpace{}\AgdaBound{x}\AgdaSpace{}\AgdaSymbol{+}\AgdaSpace{}\AgdaBound{y}%
    \\
    %
    \\
    %
    \>[2]\AgdaFunction{\texttt{\emph{eval}}}\AgdaSpace{}%
    \AgdaSymbol{:}\AgdaSpace{}%
    \AgdaDatatype{\agdamath{Expr}}\AgdaSpace{}%
    \AgdaSymbol{→}\AgdaSpace{}%
    \AgdaDatatype{Integer}\AgdaSpace{}%
    \\
    \>[2]\AgdaFunction{\texttt{\emph{eval}}}
    \AgdaSpace{}\AgdaSpace{}\AgdaSymbol{=}\AgdaSpace{}\AgdaSpace{}\AgdaFunction{\texttt{\emph{id}}}
  \end{code}
\end{centering}



Both approaches have their advantages. A deep embedding allows for the easy modification of evaluation functions without having to change the language itself. In fact, with a deep embedding, multiple evaluation functions can be given, which amounts to being able to give multiple \emph{non-compositional} (operational) semantics for the language; whether that counts as an advantage or disadvantage will depend on the context.


Meanwhile, a shallowly embedded language can only be given semantics compositionally through the host language, but the pay-off for this is that it makes it much easier to change the embedded language as a small change will not necessitate a change in the evaluation function and all its dependents.



This project, then, demands a choice of embedding strategy to be made for the two languages, viz, the imperative language to be reasoned about and the expression language within that language. Ultimately, the choice was made in favour of a \emph{deep embedding} for \emph{both}.

The justification for the imperative language to be a deep \mbox{embedding} comes from the recognition that rather than just formalising Hoare logic in Agda, this project could also have practical utility in forming a system wherein a small snippet of, say, a C program, could easily be translated into Agda, perhaps even automatically. Then a proof of its correctness could be constructed, giving great confidence in the correctness of this snippet within its original program. This made it desirable that the embedded imperative language closely mirror a simple \emph{real-world} language, lest the user of the system lose confidence that the program proved correct in Agda accurately captures the one they started with.

Another consideration is that a deep embedding of the imperative language allows for the giving of an operational semantics for that language in the form of its evaluation function. In that sense it could be said that the present work, beyond just formalising some Hoare logic, is giving both an axiomatic semantics \emph{and} an operational semantics to a simple imperative language and showing that both are consistent with one another; thus expanding the scope of the formalisation.


The decision to have the assertion language deeply embedded, however, is a little harder to justify. As this is the language that will also form the logical assertions of the predicate calculus underlying the Hoare logic, it may seem wasteful to embed this first order logic within the higher order logic underpinning Agda.

Agda already has an extensive standard library covering many of the definitions and theorems that may be needed within the Hoare logic calculus. For instance, in Hoare logic, it is often necessary to prove $\textM{P} \Rightarrow \textM{Q}$ for some \textM{P} and \textM{Q} --- e.g.\! when the user has \mbox{\gtcil{A}{S_1}{P}} and \mbox{\gtcil{Q}{S_2}{B}} and wants to derive \mbox{\gtcil{A}{S_1 \; ; S_2}{B}} --- and if, say, this \textM{P} is some conjunction involving \textM{Q}, then what is required is a mechanism/proof corresponding to \emph{conjunction elimination}. A deep embedding prevents a user from simply using the Agda standard library equivalent of conjunction elimination --- the projections out of the product/sigma type --- and instead necessitates re-proving this fact for the embedded language itself.



\pagebreak

Despite this drawback, once again the desire for this project to not only be a theoretical achievement but also to have potential practical use as a means of checking the correctness of \emph{real} programs influenced the decision in favour of a deep embedding. This is in keeping with the spirit of Hoare's original paper, in which the theory was being developed with a purpose in mind. The problem with relying on Agda's standard library is that the treatments therein don't necessarily capture real programming --- most notably in the case of integers where the standard library definition obviously corresponds to the mathematical, \emph{`true'}-integer that is unbounded in both directions, whereas in most programming languages, certainly the ones this work is aiming to reason about, an integer is bounded by dint of it being implemented by the compiler as, usually, either a 32 or 16-bit word.

Hoare was very particular in his original paper to only introduce \mbox{arithmetic} axioms that are true regardless of whether one was reasoning with the traditional infinite set of integers or within the programmer's finite sets of `integers' and regardless of the choice of overflow strategy. He also pointed to the fact that the actual arithmetic or overflow strategy could be identified via a set of mutually exclusive axioms --- a fact made use of in the \emph{proof obligation interfaces} described in the next section.

In keeping with this spirit, a deep embedding, it was reasoned, would force the user of this library to think consciously about the inferences that are being used and whether they really hold within the `real' world. The intention being that if a proof of correctness depended, say, on a particular overflow strategy, this fact would be rendered explicit on the way to constructing that proof.

The end result of these twin choices of embedding strategy is that only the Hoare logic calculus itself takes place within Agda's higher order logic, with the rest of the formalisation busying itself \emph{within} the deep embedding of one of the two languages. Despite this, there will be very little, if any, reason to use Agda's standard library and higher expressive power within the process of proving correct a simple program within this library as the rules provided should be sufficient for programs within the scope of the library's capabilities.


\pagebreak


\subsection{Proof Obligation Interfaces}


As was mentioned in the previous section, the decision to go with a deep embedding for the expression and or assertion language brings with it a major drawback. While some users may wish to rigorously prove all aspects of a program correct, ideally, the user shouldn't be \emph{forced} to re-prove simple, obvious, and banal lemmas when proving a program correct in the library.

This led to the decision to build into the formalisation/library a pair of interfaces using Agda's record types --- a generalisation of the dependent product type. These two interfaces being:


\begin{itemize}
\item \textbf{Data-Interface}: to abstract out the representation of the identifiers, values, and operations and lemmas thereupon.
\item \textbf{State-Interface}: to abstract out the representation of the state space and lemmas thereupon.
\end{itemize}


The intention of these interfaces would be twofold. First, to allow the user to forestall, perhaps indefinitely, the obligation of proving simple or obvious lemmas when proving a program correct within the library. Secondly, to separate out the concerns and hide implementation details that are adjunct to Hoare logic but not the main concern in any proof of correctness constructed therein. For example, while reasoning within the Hoare logic calculus it is undesirable to have knowledge or use of the fact that the state space is represented within the formalisation in a particular way, say, as a list of pairs of identifiers and variables, as no proof should depend on the exact choice of representation.

A sketch of the interfaces as currently defined in the library are given in figure \ref{agda:interfaces}. A user of this library would be able to add any needed lemmas to these interfaces as required for any proof of correctness being worked upon. The user that is after a total formalisation then, can go on to prove correct the added inference rules or axioms, within a given instantiation of the interface. Such an instantiation is bound by the definition of the interface to properly identify its arithmetic and overflow strategy, thus forcing the explicit consideration on the part of the user of such matters. Alternatively, the user interested only in the mechanics of the Hoare logic calculus can forgo instantiating the interface indefinitely and still prove programs correct.






\begin{figure}
  \caption{Sketch of Data-Interface and State-Interface}
  \label{agda:interfaces}
  \texttt{
    \begin{centering}
      \begin{minipage}{0.45\textwidth}
        \begin{tabbing}
           \textsc{\color{Blue} Data}\=\textsc{\color{Blue}-Inter}\=\textsc{\color{Blue}face:}\hspace{5em}\=\hspace{10em}\= \\
          \> {\color{Gray} \textsl{data:}}    \>                \>   {\color{gray}\textsl{functions:}}        \>      \\
          \> Id                                 \>: Set                      \>   WFF                              \>: Val $\rightarrow$ Set   \\
          \> Val                                \>: Set                       \>   \small{to$\mathbb{B}$Val} \>: (\=v : \!\!Val)  \\
          \> {\color{Gray}\textsl{variables:}}          \>                              \>    \>   \> $\rightarrow$ WFF v    \\
          \> \codevar{x}                    \>: Val                      \>   \>    \>  $\rightarrow$ Bool      \\ 
          \> \codevar{y}                  \>: Val   \> {\color{gray}\textsl{arith.\!\!\! rules from \cite{hoare1969axiomatic}\!:}} \> \\          
          \> \codevar{z}                     \>: Val                     \>  A1             \>: x+y$\equiv$y+x  \\
          \> {\color{gray}\textsl{constants:}}            \>                             \> \vdots         \>  \\
          \> \textnormal{\constv{0}}  \>: Val                      \> A9  \>:  x*\textnormal{\constv{1}}$\equiv$x \\ 
          \> \textnormal{\constv{1}}   \>: Val                     \> ARITHMETIC-STRATEGY  \>: \ldots  \\ 
          \> \textnormal{\constv{2}}    \>: Val                     \> OVERFLOW-STRATEGY    \>: \ldots   \\ 
          \>   {\color{gray}\textsl{operations:}}        \>       \> {\color{gray}\textsl{propositional rules:}} \> \\ 
          \>      \_||\_      \>: \ldots                                       \>  DeMorgan$_1$                \>: \ldots \\  
          \>     \_\&\&\_   \>: \ldots                                       \>  DeMorgan$_2$      \>: \ldots  \\ 
          \>    \vdots           \>                                                  \>  ConjunctionElim$_{left}$ \>: \ldots \\ 
           \> \_+\_  \>: \ldots                                                  \>  \vdots  \>  \\ 
           \>  \_*\_  \>: \ldots                                                  \>  NegationElim \>: \ldots  \\ 
        \end{tabbing}
      \end{minipage}
    \end{centering}
    \begin{centering}
      \begin{minipage}{0.45\textwidth}
        \begin{tabbing}
           \textsc{\color{Blue} State-}\=\textsc{\color{Blue}Interf}\=\textsc{\color{Blue}ace:}\hspace{6em}\=\hspace{10em}\= \\
          \> {\color{Gray} \textsl{definition of state space:}} \>           \\
          \> \textM{S}                    \>: Set                                           \\
          \> {\color{Gray} \textsl{empty/initial state:}} \>           \\
          \> \circfill                        \>: \textM{S}       \\
          \> {\color{Gray} \textsl{state operations:}} \>           \\
          \> updateState                  \> \> : Id $\rightarrow$ Val $\rightarrow$  \textM{S} $\rightarrow$  \textM{S} \\
          \> getIdVal                       \> \> : Id $\rightarrow$ \textM{S} $\rightarrow$  Maybe Val \\
          \> dropValue                    \> \> : Id $\rightarrow$ \textM{S} $\rightarrow$  \textM{S}  \\
          \> {\color{Gray} \textsl{state space lemmas as needed:}} \>           \\
          \> \vdots
        \end{tabbing}
      \end{minipage}
    \end{centering}  
  }
  
  {\footnotesize \NB that the interfaces have been instantiated in full as part of this project with \impcode{Id} \eqdef \, $\mathbb{N}$ and \impcode{Val} \eqdef \, ($\mathbb{Z}$ \impcode{x Bool}) --- where $\mathbb{N}$, $\mathbb{Z}$, and \impcode{Bool} are the Agda standard library versions. Implicit casting is then assumed between Ints and Bools within the Val type and the state space is defined as lists of pairs of \impcode{Id}'s and \impcode{Val}'s --- i.e. \textM{S} \eqdef \, ( \impcode{List} (\impcode{Id x Val})). }
\end{figure}


 
\subsection{The Expression and/or Assertion Language}
\label{sec:spec:expression-assertion-lang}

The specification of the expression language is straightforward, with the intent being that it closely mirror the array of operands available in most imperative languages. It is described, as it appears in the formalisation, via the following context-free grammar given in Backus-Naur form:


\begin{centering}
  \texttt{
    \begin{tabbing}
      <Exp>\hspace{3em}\=$\Coloneqq$ <Exp> <Op$_2$> <Exp> | <Op$_1$> <Exp> | <terminal>\\
      <Op$_2$> \>$\Coloneqq$ \&\&{\scriptsize{o}} | ||{\scriptsize{o}} | =={\scriptsize{o}} | $\leq_o$ | \ldots\,| +{\scriptsize{o}} | -{\scriptsize{o}} | \ldots\,| \%{\scriptsize{o}}\\
      <Op$_1$> \>$\Coloneqq$ ++{\scriptsize{o}} | --{\scriptsize{o}} | $\neg${\scriptsize{o}} | -{\scriptsize{o}}\\
      <terminal> \>$\Coloneqq$ const <num> | var <id> | \textM{true} | \textM{false}\\
      <num> \>$\Coloneqq$ 1 | 2 | 3 | \ldots\\
      <id> \>$\Coloneqq$ \texttt{x} | \textM{y} | \texttt{z} | \ldots
    \end{tabbing}
  }
\end{centering}

Evaluation of these expressions is defined with respect to the operator instantiations abstracted away behind the data-interface. If assertions are to be precisely expressions, however, the language given above may seem to allow for some unusual assertions that may raise an eyebrow. What do the assertions \texttt{(2 + 1)} or \text{(\texttt{x} * 5)} mean? The problem is that, as mentioned on page \pageref{page:expassertionprob}, expressions need to \emph{at least} be a subset of assertions to allow for the substitution of the former into the latter.

An incredibly baroque solution to this problem would be enforcing a type system that distinguishes between Boolean variables and Integer variables within the deep embedding. The alternative, much simpler, solution that has been opted for here is to assume implicit casting between Ints and Bools within both the expressions and the assertions, drastically simplifying both.

Following C, C++, and most other languages with implicit casting, any non-zero integer is taken to have truth-value \textM{true}, and zero, a truth-value of \textM{false}. Thus, the expressions \texttt{(2 + 4)} and \texttt{(4 * 0)} are valid assertions having constant values \textM{true} and \textM{false} respectively.


The next complication involves the handling of stuck expressions. Is the assertion (\texttt{x} == (\texttt{y} / 0)) to be read as \textM{false}? Is it even an Assertion? The assertions in Hoare Logic (or assertions in general) are understood to be boolean-valued functions over the state space, but with the present treatment some assertions are only partial functions of the state space as the truth value of any assertion with a variable is undefined in all states in which that variable is not defined; as is any assertion that contains a division by zero error.


This is a problem often brushed aside casually - if mentioned at all - in typical expositions of the subject and it is easy to see why --- any sensible programmer will avoid writing code where the non-zero-ness of a divisor is not obvious and a variable that is undefined will immediately make itself apparent. Unfortunately, in a constructive formalisation such as this one, sweeping things under the table is not an option nor desirable so the complication must be addressed.


Semantically, this problem is resolved by Dijkstra in \cite{Dijkstra76} by introducing a predicate into the expression/assertion language of the form $\textM{D(E)}$ which returns true when the given state lies within the domain of the expression \textM{E}. The weakest precondition of the assignment mechanism is then rewritten as:


\begin{center}
  $ \textM{wp( \texttt{x} \coloneqq E , R )} = \{ \textM{D(E)} \texttt{\;\;cand (sub \textM{E} x \textM{R})} \}$ 
\end{center}


\ldots with \texttt{cand} being the conditional boolean \impcode{\&\&} that only evaluates the second argument if necessary. In essence, the semantics are changed so that any stuck assertion will be rendered as \textM{false}. From the perspective of Hoare logic --- from outside the deep embedding --- this solution seems reasonable as with Hoare logic being a \emph{deductive system}, it is only whether assertions are true that is of concern, not the conditions under which they fail to be so.

With that said, this only answers the question of how stuck expressions are to be treated \emph{semantically}, not how to handle the issue \emph{syntactically} within this formalisation. Perhaps \textM{D(E)} could be added to the expression language, as the \emph{well-formed-ness} of an expression in a given state can be defined inductively and checked mechanically. However, making this change would also change the semantics of the imperative language that is also to be embedded.


It is obviously undesirable to have `(\texttt{x} == (\texttt{y} / 0)) \eqdef \; \textM{false}' within the semantics of the \emph{programming} language that users of this library are to form the programs they want to prove correct, as no sensible language should allow \mbox{`\impcode{if ( ¬ (\texttt{x} == (\texttt{y} / 0))) \ldots}'} to evaluate\footnote{What on earth would it even evaluate to?}  - not to mention the fact that this would be a deviation from the intention outlined previously for the formalised imperative language to mirror real world languages.


So the desired state of affairs is to have stuck expressions be undefined within the programming language, but equate them to false without.  The solution used to achieve this was to modify the data interface so that all operations --- and by extension the expression \texttt{eval} function --- had the option of failing via wrapping the output of each in the \impcode{Maybe} type. 


With this decision made, the definition of a \emph{well-formed-formula} could be given simply in terms of evaluation. i.e.\!\! an expression/assertion is a well-formed formula if and only if it can be evaluated successfully:

{\advance\leftskip\mathindent
  \advance\leftskip\mathindent
  
\input{agda-snippets/assertions-wff-def}

}

Wth that in place, an assertion \emph{proper} for the sake of Hoare logic can be represented as follows:


{\advance\leftskip\mathindent
  \advance\leftskip\mathindent

\input{agda-snippets/assertions-assert-def-2}

}

\vspace{-1.5em}

That is, to assert an expression/assertion is to prove it a WFF such that this WFF has truth value \textM{true}. This allows a definition to be given of what it means for one assertion to imply another:

{\advance\leftskip\mathindent
  \advance\leftskip\mathindent

  \input{agda-snippets/assertions-implication}

  \vspace{-1.5em}
}

 Followed finally by an inference example showcasing how assertions are to be embedded and manipulated within the library:


{\centering
  
  \begin{tabular}{cc}
    \centering
    \begin{minipage}[t]{0.45\textwidth}
      \centering
      \input{agda-snippets/assertions-a1-def}
    \end{minipage}

    &
   
      \begin{minipage}[t]{0.45\textwidth}
        \centering
        \input{agda-snippets/assertions-a2-def}
      \end{minipage}
       
    \\
    
    \multicolumn{2}{c}{
    \begin{minipage}{0.9\textwidth}
      \centering
      \vspace{-0.5cm}
      \input{agda-snippets/assertions-inference-proof}
    \end{minipage}}
 
  \end{tabular}
}


\subsection{The `Mini-Imp' Programming Language}

The design and embedding of the imperative language is far simpler than that of the expression language. A simple while-language coined `Mini-Imp' was devised containing only the programming constructs that are present in \cite{hoare1969axiomatic} and \cite{Dijkstra76} only without non-determinism present in the iterative (\impcode{while\_do\_}) and alternative (\impcode{if\_then\_else\_}) commands; again, this is in keeping with the intention for the language to closely mirror simple real-world languages. The programming constructs themselves are defined as state transformers (\stateT) with a program being a non-empty sequence of these state transformers:

{
  \advance\leftskip2\mathindent
  \input{agda-snippets/mini-imp-definition}
}

  \vspace{-1em}

The overloaded terminator/separator construct allows for the terse and familiar encoding of programs but does, however, necessitate a third function for program composition which as it turns out is simply list concatenation:

{\advance\leftskip2\mathindent
  \input{agda-snippets/mini-imp-then-def}
  \vspace{-3em}
  \input{agda-snippets/mini-imp-then-comm}
}

With both the expression language and Mini-Imp defined, see figure \ref{fig:programexamples} for some examples of full programs encoded within the Agda library.

\pagebreak

\begin{figure}
  \caption{Some simple programs defined with Mini-Imp; ripe for reasoning!}
  \label{fig:programexamples}

\begin{tabular}{r|l}
  \centering
  \footnotesize
\begin{minipage}[t]{0.4\textwidth}
  \centering
  \input{agda-snippets/example-progs-gcd}
\end{minipage}

& 
   
\begin{minipage}[t]{0.5\textwidth}
  \centering
  \footnotesize
  \advance\leftskip0.2cm
  \input{agda-snippets/example-progs-mul-add}
\end{minipage}

\end{tabular}

\end{figure}


The end result of these two deep embeddings then, is that programs can be encoded directly within Agda (see figure \ref{fig:programexamples})  in a manner that is imminently intelligible; something that cannot often be said of Agda syntax.

\subsection{The Rules to be Implemented}

With the Mini-Imp language specified a rough sketch of the rules to be formalised can be given with the apparatus supporting these Agda definitions to be expounded upon in the next section. First, the axiom of assignment:

\vbox{\centering
  \input{agda-snippets/rules-axiom-of-assi}
}

Follwed by the two rules of consequence (`D1-Rule-of-Consequence-pre' is omitted as it has the obvious corresponding form to the one below):

\vbox{\centering
  \input{agda-snippets/rules-cons-post}
}


Then the rule of composition for the chaining of Hoare triples together.\footnote{\NB That \pctrip{P}{Q}{R} is the notation within the codebase for \mbox{\gtcil{P}{Q}{R}} as `\{' and `\}' are reserved for Agda's syntax.}

\vbox{\centering
  \input{agda-snippets/rules-comp}
}

And finally, most interestingly, the iterative and alternative rules:

\vbox{\centering
  \input{agda-snippets/rules-while}
}

\vspace{-1em}

\vbox{\centering
  \input{agda-snippets/rules-conditional}
}

And with that, the Hoare logic inference rules that are to be formalised within this work have been specified.





\section{Implementation Details}

With the syntactic aspects out the way, this section covers the semantics of those syntactic aspects as well as some of the more nuanced or tricky aspects of the formalisation.


\subsection{Small-step Evaluation \& Termination}

As mentioned in section \ref{sec:shallowdeep}, the deep embedding of the Mini-Imp language needs some form of observation or evaluation function to give it semantics. This presented a challenge as Agda demands that all functions be total and features a rather strict termination checker that will only accept functions that it can mechanically prove terminating. Said termination checker only checks for \emph{structural recursion}, and so some argument of the evaluation function must get structurally smaller on each call. This left the only feasible way forward being to give the Mini-Imp language semantics via a \mbox{small-step} \mbox{(operational)} semantics which then allowed for the evaluation function to take a `fuel' argument ($\in \mathbb{N}$) that could be decremented with each call, \mbox{giving} the form: \AgdaFunction{ssEvalwithFuel}\AgdaSpace{}\AgdaSymbol{:}\AgdaSpace{}\AgdaDatatype{ℕ}\AgdaSpace{}\AgdaSymbol{→}\AgdaSpace{}\AgdaFunction{Program}\AgdaSpace{}\AgdaSymbol{→}\AgdaSpace{}\AgdaField{S}\AgdaSpace{}\AgdaSymbol{→}\AgdaSpace{}\AgdaDatatype{Maybe}\AgdaSpace{}\AgdaField{S}. The implementation of this function is straightforward, if a little verbose, with the two most interesting cases reproduced below and the full implementation given in figure \ref{fig:eval-full} in the appendix.

\vspace{-1em}

{\centering
\input{agda-snippets/evaluation-eval-while-case}

\vspace{-3.2em}

\input{agda-snippets/evaluation-eval-while-c2-case}
}


With a small-step evaluation function defined, what it means for a program to terminate can now be formalised like so:\footnote{\NB That \AgdaFunction{C} is introduced here as a type synonym for \AgdaFunction{Program}.}


{\advance\leftskip1.5\mathindent

\input{agda-snippets/termination-termination-def}

\vspace{-0.8cm}

\input{agda-snippets/termination-termination-cond-def}

\vspace{-0.8cm}

\input{agda-snippets/termination-indexed}

\vspace{-0.8cm}

\input{agda-snippets/termination-indexed-cond}

}



The different notations above are just different ways of saying the same thing, viz, that a program terminates if there exists some $n \in \mathbb{N}$ such that the evaluation of the program succeeds with fuel $= n$. With this constructive definition of termination, some useful lemmas for later use in formalising the Hoare logic rules were proved:

\hspace{1em}

{\small \input{agda-snippets/termination-eval-det-signature}}

The above function relates any two proofs of termination of the same program from the same initial state via identifying the resultant states. This can be taken as a proof that evaluation is deterministic --- which it obviously is --- hence the name \AgdaFunction{EvalDet}.\footnote{The implementation/proof of this function is given in figure \ref{fig:evaldetfull} in the Appendix.} Closely related is the \AgdaFunction{addFuel} function below that takes any proof of termination and generates a new proof of termination with a given extra amount of fuel. The implementation of both of these lemmas is fairly straightforward albeit tedious, with the central mechanism being induction on the structure of \AgdaFunction{C}. Both lemmas are used in the constructive proof of the \AgdaFunction{D3-While-Rule} (see figure \ref{fig:while-rule-proof}).

{\,
\begin{minipage}{0.9\textwidth}
{\input{agda-snippets/termination-add-fuel.tex}}
\end{minipage}
}






\subsection{Termination Proof Splitting}


On the topic of termination, a key lemma that is utilised within the proof of both the \AgdaFunction{D3-While-Rule} and the \AgdaFunction{D2-Rule-of-Composition} is the mechanism \mbox{\AgdaFunction{⌊ᵗ⌋-split}}\footnote{The implementation/proof of this function is given in figure \ref{fig:tsplitfull} in the Appendix.} that takes a proof of termination of some program of the form `$Q_1 \; \AgdaFunction{\impcode{THEN}} \; Q_2$' and outputs the following \mbox{\AgdaFunction{Split-⌊ᵗ⌋}} record:


{\centering \input{agda-snippets/termination-tsplit-record}}

\vspace{-1em}

That is, it `splits' a proof of termination into two proofs of termination of the two constituent parts. It is only the $\Delta$ component that is necessary within the rule of composition as a means of identifying the resultant state of \pctrip{R_1}{Q_2}{R} with the resultant state of \pctrip{P}{\,Q_1 \;\impcode{THEN}\; Q_2\,}{R}. On the other hand, for the while rule, the full record is needed.



\subsection{Hoare Triples in Agda}

With termination covered, it is now possible to give the definition Hoare triples within the Agda library. The choice of notation is a result of the curly braces being reserved for Agda's syntax and so \pctrip{P}{Q}{R} and \tctrip{P}{Q}{R} are used for partial and total correctness respectively.

{\centering \input{agda-snippets/semantics-pc-trip}}

\vspace{-2em}

{\centering \input{agda-snippets/semantics-tc-trip}}


\subsection{Axiom of Assignment}

Rather than go into detail of the proofs of each and every rule, only the proofs of \AgdaFunction{D0-Axiom-of-Assignment} and \AgdaFunction{D3-While-Rule} are detailed in this report, as these are the most salient rules.


The formulation of the axiom of assignment first requires the construction of a function that substitutes an expression into an assertion but given that assertions are synonymous with expressions here, this function has signature: \mbox{\AgdaFunction{sub : Exp $\rightarrow$ Id $\rightarrow$ Exp $\rightarrow$ Exp}.} The proof of \AgdaFunction{D0-Axiom-of-Assignment}, then, isn't too complicated, with the key mechanisms within the proof being two lemmas that were added to the state interface:

\begin{itemize}
  \small
\item \AgdaField{updateGet}\AgdaSpace{}\AgdaSymbol{:}\vspace{0.5\baselineskip}\\
  \hspace*{6em}\AgdaSymbol{∀}\AgdaSpace{}\AgdaBound{i}\AgdaSpace{}\AgdaBound{v}\AgdaSpace{}\AgdaBound{s}\AgdaSymbol{→}\AgdaSpace{}\AgdaField{getIdVal}\AgdaSpace{}\AgdaBound{i}\AgdaSpace{}\AgdaSymbol{(}\AgdaField{updateState}\AgdaSpace{}\AgdaBound{i}\AgdaSpace{}\AgdaBound{v}\AgdaSpace{}\AgdaBound{s}\AgdaSymbol{)}\AgdaSpace{}\AgdaOperator{\AgdaDatatype{≡}}\AgdaSpace{}\AgdaInductiveConstructor{just}\AgdaSpace{}\AgdaBound{v}
\item \AgdaField{ignoreTop}\AgdaSpace{}\AgdaSymbol{:}\AgdaSpace{}\vspace{0.5\baselineskip}\\
  \hspace*{0.1em}\AgdaSymbol{∀}\AgdaSpace{}\AgdaBound{i}\AgdaSpace{}\AgdaBound{v}\AgdaSpace{}\AgdaBound{x}\AgdaSpace{}\AgdaSymbol{→}\AgdaSpace{}\AgdaOperator{\AgdaFunction{¬}}\AgdaSpace{}\AgdaBound{i}\AgdaSpace{}\AgdaOperator{\AgdaDatatype{≡}}\AgdaSpace{}\AgdaBound{x}\AgdaSpace{}\AgdaSymbol{→}\AgdaSpace{}\AgdaSymbol{(}\AgdaBound{s}\AgdaSpace{}\AgdaSymbol{:}\AgdaSpace{}\AgdaField{S}\AgdaSymbol{)}\AgdaSpace{}\AgdaSymbol{→}\AgdaField{getIdVal}\AgdaSpace{}\AgdaBound{x}\AgdaSpace{}\AgdaSymbol{(}\AgdaField{updateState}\AgdaSpace{}\AgdaBound{i}\AgdaSpace{}\AgdaBound{v}\AgdaSpace{}\AgdaBound{s}\AgdaSymbol{)}\AgdaSpace{}\AgdaOperator{\AgdaDatatype{≡}}\AgdaSpace{}\AgdaField{getVarVal}\AgdaSpace{}\AgdaBound{x}\AgdaSpace{}\AgdaBound{s}
\end{itemize}

That is, any state space implementation must satisfy the above, fairly intuitive, lemmas for the axiom of assignment to hold. Both have been implemented within the `state as list' representation as part of this \mbox{formalisation.}


\subsection{The Rule of Iteration / While Rule}

The proof/implementation of \AgdaFunction{D3-While-Rule} is a little more involved, but the basic mechanism is similar to that of the proofs relating to termination/evaluation of programs, with induction being performed on the structure of a \AgdaFunction{Program}. The most salient mechanism as mentioned in the previous section is the use of the \mbox{\AgdaFunction{⌊ᵗ⌋-split}} function. This function is needed for the case where the condition $B$ of the while loop is true and therefore the body of the loop is evaluated. Under this case, the (assumed) proof of termination reduces to: \mbox{\AgdaOperator{\AgdaFunction{⌊ᵗ}}\AgdaSpace{}\AgdaBound{ℱ}\AgdaSpace{}\AgdaOperator{\AgdaFunction{⸴}}\AgdaSpace{}\AgdaSymbol{(}\AgdaBound{C}\AgdaSpace{}\AgdaOperator{\AgdaFunction{𝔱𝔥𝔢𝔫}}\AgdaSpace{}\AgdaOperator{\AgdaInductiveConstructor{𝔴𝔥𝔦𝔩𝔢}}\AgdaSpace{}\AgdaBound{B}\AgdaSpace{}\AgdaOperator{\AgdaInductiveConstructor{𝒹ℴ}}\AgdaSpace{}\AgdaBound{C}\AgdaSpace{}\AgdaOperator{\AgdaInductiveConstructor{;}}\AgdaSymbol{)}\AgdaSpace{}\AgdaOperator{\AgdaFunction{⸴}}\AgdaSpace{}\AgdaBound{s}\AgdaSpace{}\AgdaOperator{\AgdaFunction{ᵗ⌋}}} but for the recursive call a proof of termination of the form: \mbox{\AgdaOperator{\AgdaFunction{⌊ᵗ}}\AgdaSpace{}\AgdaBound{ℱ}\AgdaSpace{}\AgdaOperator{\AgdaFunction{⸴}}\AgdaSpace{}\AgdaSymbol{(}\AgdaOperator{\AgdaInductiveConstructor{𝔴𝔥𝔦𝔩𝔢}}\AgdaSpace{}\AgdaBound{B}\AgdaSpace{}\AgdaOperator{\AgdaInductiveConstructor{𝒹ℴ}}\AgdaSpace{}\AgdaBound{C}\AgdaSpace{}\AgdaOperator{\AgdaInductiveConstructor{;}}\AgdaSymbol{)}\AgdaSpace{}\AgdaOperator{\AgdaFunction{⸴}}\AgdaSpace{}\AgdaBound{s}\AgdaSpace{}\AgdaOperator{\AgdaFunction{ᵗ⌋}}} is needed. Obviously it is the case that if the former terminates with $f$ fuel then so will the latter and so the \mbox{\AgdaFunction{⌊ᵗ⌋-split}} function, along with \mbox{\AgdaFunction{addFuel}}, and \mbox{\AgdaFunction{EvalDet}}, is used to transform the proof of the former into a proof of the latter.\footnote{ \NB That the full implementations/proofs of the axiom of assignment and the While Rule are reproduced in the appendix in figures \ref{fig:axiom-of-assi-proof}, and \ref{fig:while-rule-proof} respectively.}




\subsection{Relation to Predicate Transformer Semantics}

In \cite{Dijkstra76} Dijkstra outlines some properties that the notion of \textM{wp} and \textM{wlp} must satisfy to make sense as a means of giving semantics to a mechanism and or programming construct. Failure to satisfy these properties would mean we were no longer manipulating pre/post-conditions but instead just 'massaging predicates.'

These properties are proved classically in that exposition but given the scope of this project, it seemed natural to consider including these properties in the formalisation as a means of sanity checking the formalisations of the Mini-Imp mechanisms that have been defined.

However, the constructs/mechanisms that have been formalised here ( $\coloneqq$ ,  \impcode{if\_then\_else\_, while\_do\_} \ldots ) have been formalised in terms of how they are to be executed, which is precisely the approach to defining programming constructs that the notions of \textM{wp}  and \textM{wlp} were trying to avoid. So there is an incongruency there.

  The only mechanism for which \textM{wp}/\textM{wlp} have come close to being formalised is the assignment ($\coloneqq$) mechanism via the \AgdaFunction{sub} function. This is because the \AgdaFunction{sub} function actually \emph{is} the weakest precondition.

\begin{center}
  
  i.e.\!\! \mbox{\textM{wp}($ i \coloneqq e$ , \textM{R} ) = \AgdaFunction{sub} $e$ $i$ \textM{R}}

\end{center}


With that said, while the \AgdaFunction{sub} function has been formalised, the fact that it \emph{is} the weakest precondition hasn't been. What has been formalised is the fact that \mbox{\AgdaFunction{sub} $e$ $i$ \textM{R} $\Rightarrow$ \textM{wp}( $ i \coloneqq e$ , \textM{R} )}, via the proof of the axiom of assignment.

For the rest of the mechanisms, however, no attempt has been made to formalise their corresponding \textM{wp}/\textM{wlp}. Nonetheless, it may be within reach to confirm the \textM{wp}-properties for just the \textM{wp} that has been defined, viz the \AgdaFunction{sub} function. This proves to be trivial for property 1, the so called `Law of the Excluded Miracle' (\textM{wp(S, \agdamath{F}) = \agdamath{F}} )  \ldots

{\centering \input{agda-snippets/semantics-lem}}

\ldots and trivial for the second property of monotonicity, with the proof not reproduced here. In fact, after this second property was confirmed it became clear that this was a detour from the project scope that was adding little value to the formalisation so the exploration of the formalisation's relationship to predicate transformer semantics stopped there.


\begin{figure}
  \caption{Using the library to formalise the correctness of the \impcode{SWAP} program: \;\; \impcode{[1/3]}}
  \label{fig:swap-proof}
  \hrulefill 
  {\centering \input{agda-snippets/swap-example-p1}}
\end{figure}

\begin{figure}\ContinuedFloat
  \caption{\mbox{Using the library to formalise the correctness of \impcode{SWAP} program cont. \;\; \impcode{[2/3]}} }
  \hrulefill\\
  \vspace{1em}\\
  \hspace*{\fill} {\Huge\vdots} \hspace*{\fill}
  {\centering \input{agda-snippets/swap-example-p2}}
  \hspace*{\fill} {\Huge\vdots} \hspace*{\fill}
\end{figure}

\begin{figure}\ContinuedFloat
  \caption{\mbox{Using the library to formalise the correctness of \impcode{SWAP} program cont. \;\; \impcode{[3/3]}} }  
  \hrulefill \\
  \vspace{2.5em}\\
  \hspace*{\fill} {\Huge\vdots} \hspace*{\fill}
  {\centering \input{agda-snippets/swap-example-p3}}
\end{figure}



\section{Project Evaluation}

\subsection{Using the System to Reason about Programs}

With the Hoare logic rules implemented, proofs of program correctness can now be constructed using the Agda library that has been developed.

Only a simple example has been constructed, a proof of correctness of the \impcode{SWAP} program, of the form shown below. See figure \ref{fig:swap-proof} for the actual proof.


{\centering \small \input{agda-snippets/example-prog-pre}}

\vspace{-2em}

{\hspace*{10em} \begin{minipage}{0.8\textwidth} \small \input{agda-snippets/example-prog-mid} \end{minipage}}

\vspace{-2em}

{\centering \small \input{agda-snippets/example-prog-post}}

While this is a very simple and meagre example that doesn't even utilise the While Rule, it is sufficient for evaluating the use of the Agda library that has been produced for the task of formalising proofs of correctness of simple programs. The process, ultimately, even for incredibly simple programs, is rather tedious as it forces the user to think very carefully and belabour with great assiduity. In the end, more time is spent manipulating syntax than convincing oneself of correctness, but perhaps that is to be expected when one considers that the task in a formalisation such as this one is ultimately to convince the \emph{machine} of the correctness, not the user.


\subsection{Deliverables}
\label{sec:deliv}

The most salient achievement of this project, then, is a novel and constructive formalisation of a selection of Hoare logic inference rules in Agda. This has been achieved with a deep embedding of a simple \emph{while} language `Mini-Imp.' This language was given an operational semantics via a small-step evaluation function \emph{and} an axiomatic semantics via the Hoare logic rules thus demonstrating, nay, \emph{formalising} the interplay and or consistency between the two approaches to programming language semantics. In terms of practical utility the Agda library as a system for reasoning about programs leaves a lot to be desired, but perhaps with much more work it could prove a useful building block for a much more useful tool.



\subsection{Reflection on the use of Agda}

Reflecting on the usage of Agda for this project, there are some clear positives and negatives. One positive is Agda's support for unicode in source code that allows for some beautiful proofs. With great power, however, comes great responsibility and one shouldn't use fancy unicode characters just because one \emph{can} --- a rule that was fallen afoul of more than a few times --- but rather, it was learned, only when they can provide greater clarity or terseness.

On that note, an interesting observation is that frequently the aesthetic nature of a signature rendered in all its unicode splendour led to a reluctance to sanity check it semantically --- even after hours spent in vain trying to prove it. This psychological bias, once noticed, was overcome by paying closer attention to the semantic content of a signature rather than its syntactic form and also by spending more time considering the signatures themselves before charging in and attempting to prove something syntactically pretty but semantically absurd.

Finally, an oft encountered negative of Agda was the verbose and unhelpful nature of its reporting of goal types. Perhaps this was just a problem particular to this project, but at times, upon asking for the type of a hole in a proof while constructing a proof interactively, a myriad of symbols was produced as a result of Agda fully unpacking all the declarations. See figure \ref{fig:verbosity} in the appendix for an example.

\subsection{Missteps \& Drawbacks}

Many wrong turns were taken on the way to completing this project. Of the most notable was an initial insistence on enforcing a type system within the assertion language without impacting the expression language. The desire was for \texttt{`x + 5'} and other integer valued expressions to \emph{not} be valid assertions but eventually it was realised that the formalisation became far simpler and terser once implicit casting between integers and booleans was assumed.

A big drawback of the current system, somewhate mitigated by the proof obligation interfaces, is the need to formalise simple and obvious lemmas of the assertion language. The cumbersome necessity of formalising the obvious, however, is part and parcel of most formalisations so is not worth much commentary here.

Another shortcoming is the inability to specify the free or non-free variables of an expression and or assertion. Such a facility would allow the proof of correctness of the \impcode{SWAP} program to be generalised over expressions. With the current formulation, \impcode{SWAP} cannot be said to swap the values of 𝒙 and 𝒚 if their initial values 𝑿 and 𝒀 are described by arbitrary expressions as, being arbitrary, they may contain 𝒙 or 𝒚. Relatedly, the only variables available for program specification currently are 𝒙, 𝒚, and \codevar{z} with extra variables needed to be added as required. This is clunky and ideally some facility or interface would exist that would allow a user the functionality described as `give me a fresh variable' or, `give me a fresh variable that is not used in this expression \textM{E}.' Such functionality, however, is left for possible future work.



\subsection{Future Work}

As mentioned in section \ref{sec:deliv}, the present work is not all that useful in practice. With considerably more work, this library could be a useful tool for proving correct \emph{very} simple programs, the issues addressed in the previous section would need to be addressed, however. Perhaps some semi-automated tool could be developed to at least ease the burden of having to transcribe program snippets into Agda or the pain of tedious syntax manipulation; the final output of the tool being a proof checkable by Agda.

In terms of the formalisation, the next step beyond fixing the issues mentioned prior would be expanding the system with Separation Logic. This would allow for the manipulation of assertions containing pointers and claims upon the heap space, rather than just the values of local variables. In theory this is imminently achievable, but in practice may prove otherwise.


\subsection{Conclusion \& Personal Reflection}


If the authors whose works made up much of the literature referenced in this report could comment on this work, a `we told you so' would be more than justified. Each one at some point in the papers or monographs read in preparation for this project mentioned the need for `a fine balance' between `formality and common sense' and it's fair to say that the scales have tipped away from common sense and towards formality in this project and as a result the most `practical' output of this work is a three-page proof of the correctness of the \impcode{SWAP} program.

But as I now believe, the central purpose of a constructive formalisation isn't in practicality but in the education and entertainment of the person doing the constructing and in that sense, the project is a great success.


\bibliographystyle{plain}

\bibliography{report}

\pagebreak


\begin{centering}

  \vspace*{\fill}
  \textbf{\huge 5 \, Appendix}
  \vspace*{\fill}
  
\end{centering}


\pagebreak


\begin{figure}
  \caption{The full definition of the small-step evaluation function \;\; \impcode{[1/2]}}
  \label{fig:eval-full}
  \centering
  \input{agda-snippets/evaluation-eval-full-p1}
  {\centering \hfill \Huge{\vdots} \hfill }
\end{figure}

\begin{figure}\ContinuedFloat
  \caption{The full definition of the small-step evaluation function cont. \;\; \impcode{[2/2]}}
  \centering
  { \hfill \Huge{\vdots} \hfill }
  \input{agda-snippets/evaluation-eval-full-p2}
\end{figure}


\begin{figure}
  \caption{The full proof/implementation of the Axiom of Assignment.}
  \label{fig:axiom-of-assi-proof}
  {\centering \input{agda-snippets/rules-assi-proof}}
\end{figure}



\begin{figure}
  \caption{The full proof of the `While Rule'/`Rule of Iteration' \;\; \impcode{[1/2]}}
  \label{fig:while-rule-proof}
  \centering
  \input{agda-snippets/rules-while-proof-p1}
  {\centering \hfill \Huge{\vdots} \hfill }
\end{figure}

\begin{figure}\ContinuedFloat
  \caption{The full proof of the `While Rule'/`Rule of Iteration' \;\; \impcode{[2/2]}}
  \vspace{-0.8cm}
  \begin{center}\!\!\!\small{cont.}\end{center}
  {\centering \hfill \Huge{\vdots} \hfill }
   \centering
   \input{agda-snippets/rules-while-proof-p2}
\end{figure}

\begin{figure}
  \caption{The proof/implementation of \AgdaFunction{EvalDet}.
    \\ \NB that the $\dagger$ function is the function that extracts the witness from the proof of termination - i.e. the resultant state after the computation has terminated successfully.}
  \label{fig:evaldetfull}
  \centering
  \footnotesize
  \input{agda-snippets/termination-eval-det-full}
\end{figure}

\begin{figure}
  \caption{The proof/implementation of \mbox{\AgdaFunction{⌊ᵗ⌋-split}} \;\; \impcode{[1/3]} \\
    \NB some cases have been omitted but none that vary from the general pattern here.}
  \label{fig:tsplitfull}
  \footnotesize
  {\centering \input{agda-snippets/termination-tsplit-full-p1}}
  {\centering \hfill \Huge{\vdots} \hfill }
\end{figure}


\begin{figure}\ContinuedFloat
  \caption{The proof/implementation of \mbox{\AgdaFunction{⌊ᵗ⌋-split}} \;\; \impcode{[2/3]} \\
   \NB some cases have been omitted but none that vary from the general pattern here. }
  \footnotesize
  {\centering \hfill \Huge{\vdots} \hfill }
  {\centering \input{agda-snippets/termination-tsplit-full-p2}}
  {\centering \hfill \Huge{\vdots} \hfill }
\end{figure}

\begin{figure}\ContinuedFloat
  \caption{The proof/implementation of \mbox{\AgdaFunction{⌊ᵗ⌋-split}} \;\; \impcode{[3/3]} \\
   \NB some cases have been omitted but none that vary from the general pattern here. }
  \footnotesize
  {\centering \hfill \Huge{\vdots} \hfill }
  {\centering \input{agda-snippets/termination-tsplit-full-p3}}
\end{figure}


\begin{figure}
  \caption{An example of the verbosity that was sometimes encountered when Agda reported the type of a hole that was semantically simple, yet syntactically complex.}
  \label{fig:verbosity}
  \vspace*{\fill}
  \begin{centering}
    \includegraphics[scale=0.50]{./Figures/verbosity}
  \end{centering}
  \vspace*{\fill}
  
\end{figure}


\end{document}

